{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lubaochuan/ml_python/blob/main/bayes_rule_intro.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zeYOyZNfP06s"
      },
      "source": [
        "# Introduction to Bayesian Inference\n",
        "\n",
        "### Part 1: The Mathematical Foundation\n",
        "Bayes' Rule allows us to update the probability of a hypothesis ($H$) based on new evidence ($E$).\n",
        "\n",
        "$$\n",
        "\\begin{align}\n",
        "P(H|E) & = \\frac{P(E|H) \\cdot P(H)}{P(E)}\\\\\n",
        "& = \\frac{P(E|H) \\cdot P(H)}{P(EH)+P(E-H)}\\\\\n",
        "& =\\frac{P(E|H) \\cdot P(H)}{P(E|H) \\cdot P(H)+P(E|-H) \\cdot P(-H)}\n",
        "\\end{align}\n",
        "$$\n",
        "\n",
        "* **P(H|E)**: Posterior - What we believe after seeing evidence.\n",
        "* **P(E|H)**: Likelihood - How likely the evidence is if the hypothesis is true.\n",
        "* **P(H)**: Prior - Our initial belief before seeing evidence.\n",
        "* **P(E)**: Evidence - Total probability of the evidence occurring.\n",
        "* **P(E|-H)**: False positive rate."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l9X-CgK8P06u"
      },
      "source": [
        "### Part 2: The Rare Disease Paradox\n",
        "We test for a disease affecting 1% of people. The test is 99% accurate (Sensitivity) but has a 5% false positive rate.\n",
        "\n",
        "**Sensitivity** (also known as the true positive rate) is the probability that a test will yield a **positive** result given that the person or item actually has the condition or attribute being tested for.\n",
        "\n",
        "For example, if a disease test has a sensitivity of 99%, it means that 99% of people who *actually have the disease* will test positive.\n",
        "\n",
        "The **false positive rate** is the probability that the test incorrectly reports a positive result for someone who actually does *not* have the condition.\n",
        "\n",
        "It is directly related to the **specificity** of a test. Specificity is the probability that a test will yield a *negative* result given that the person does NOT have the disease. In simpler terms:\n",
        "\n",
        "**False Positive Rate = 1 - Specificity**\n",
        "\n",
        "For example, if a test has a specificity of 90%, it means that 90% of healthy individuals will correctly test negative. The remaining 10% of healthy individuals will incorrectly test positive, which is the false positive rate.\n",
        "\n",
        "Both sensitivity and specificity come from the inherent imperfections or design of a diagnostic test."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ywVOGs0XP06v"
      },
      "outputs": [],
      "source": [
        "prior_disease = 0.01\n",
        "sensitivity = 0.99\n",
        "false_pos_rate = 0.05\n",
        "\n",
        "p_evidence = (sensitivity * prior_disease) + (false_pos_rate * (1 - prior_disease))\n",
        "posterior = (sensitivity * prior_disease) / p_evidence\n",
        "\n",
        "print(f\"Probability of disease given positive test: {posterior:.2%}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "11abceac"
      },
      "source": [
        "**Annotation:**\n",
        "\n",
        "This code block demonstrates how to calculate the posterior probability of having a rare disease using Bayes' Theorem. Let's break it down:\n",
        "\n",
        "1.  **`prior_disease = 0.01`**: This variable sets the *prior probability* of a randomly selected person having the disease to 1%.\n",
        "2.  **`sensitivity = 0.99`**: This is the test's *sensitivity*, representing the probability of a positive test result given that the person actually has the disease (P(E|H)).\n",
        "3.  **`false_pos_rate = 0.05`**: This is the *false positive rate*, which is the probability of a positive test result given that the person does NOT have the disease (P(E|not H)).\n",
        "4.  **`p_evidence = (sensitivity * prior_disease) + (false_pos_rate * (1 - prior_disease))`**: This calculates the *total probability of evidence* (P(E)), which is the probability of getting a positive test result overall. It accounts for both true positives and false positives.\n",
        "5.  **`posterior = (sensitivity * prior_disease) / p_evidence`**: This is the application of Bayes' Theorem. It calculates the *posterior probability* (P(H|E)), which is the probability of actually having the disease given that the test result is positive.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_2eMTCVFP06w"
      },
      "source": [
        "### Part 3: Simple Spam Filtering\n",
        "Using a **Naive Bayes** approach to check for multiple suspicious words."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pxa5nVURP06w"
      },
      "outputs": [],
      "source": [
        "def classify_spam(words, p_spam, word_probs_spam, word_probs_ham):\n",
        "    p_ham = 1 - p_spam\n",
        "    likelihood_spam = p_spam\n",
        "    likelihood_ham = p_ham\n",
        "\n",
        "    for word in words:\n",
        "        # Using .get() with 0.1 as a default 'smoothing' value for unknown words\n",
        "        likelihood_spam *= word_probs_spam.get(word, 0.1)\n",
        "        likelihood_ham *= word_probs_ham.get(word, 0.1)\n",
        "\n",
        "    return likelihood_spam / (likelihood_spam + likelihood_ham)\n",
        "\n",
        "# Data\n",
        "p_s = 0.3\n",
        "w_spam = {'winner': 0.6, 'money': 0.5, 'urgent': 0.7}\n",
        "w_ham = {'winner': 0.01, 'money': 0.05, 'urgent': 0.02}\n",
        "\n",
        "test_email = ['winner', 'money', 'urgent']\n",
        "result = classify_spam(test_email, p_s, w_spam, w_ham)\n",
        "print(f\"Spam Probability for {test_email}: {result:.2%}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "49c8377b"
      },
      "source": [
        "**Annotation:**\n",
        "\n",
        "This code block implements a simplified Naive Bayes approach for classifying an email as spam or not spam, based on the presence of certain words. Let's break it down:\n",
        "\n",
        "1.  **`def classify_spam(words, p_spam, word_probs_spam, word_probs_ham):`**\n",
        "    *   This defines a function that takes the following arguments:\n",
        "        *   `words`: A list of words from the email to be classified.\n",
        "        *   `p_spam`: The prior probability that *any* email is spam.\n",
        "        *   `word_probs_spam`: A dictionary where keys are words and values are the probabilities of those words appearing in a spam email (P(word|Spam)).\n",
        "        *   `word_probs_ham`: A dictionary similar to `word_probs_spam`, but for ham (non-spam) emails (P(word|Ham)).\n",
        "\n",
        "2.  **`p_ham = 1 - p_spam`**: Calculates the prior probability of an email being ham.\n",
        "\n",
        "3.  **`likelihood_spam = p_spam`** and **`likelihood_ham = p_ham`**: These initialize the likelihoods with the prior probabilities. As the function iterates through words, these will be updated by multiplying them with the likelihoods of each word, effectively applying a form of Bayes' theorem.\n",
        "\n",
        "4.  **`for word in words:`**\n",
        "    *   The code iterates through each word in the `test_email`.\n",
        "    *   **`likelihood_spam *= word_probs_spam.get(word, 0.1)`**: For each word, it multiplies the current `likelihood_spam` by the probability of that word appearing in a spam email. The `.get(word, 0.1)` part is a simple 'smoothing' technique; if a word is not found in `word_probs_spam`, it assumes a default probability of 0.1 instead of 0, which prevents the entire likelihood from becoming zero if an unknown word is encountered.\n",
        "    *   **`likelihood_ham *= word_probs_ham.get(word, 0.1)`**: Does the same multiplication for ham emails.\n",
        "\n",
        "5.  **`return likelihood_spam / (likelihood_spam + likelihood_ham)`**: After processing all words, this calculates the final posterior probability of the email being spam. This is a simplified application of Bayes' rule: P(Spam|Words) = P(Words|Spam) * P(Spam) / P(Words), where P(Words) is approximated by the sum of P(Words|Spam)P(Spam) and P(Words|Ham)P(Ham)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Hg1k6w4P06w"
      },
      "source": [
        "### Part 4: Student Exercise\n",
        "**Scenario:** A self-driving car sensor detects an obstacle.\n",
        "* Prior Obstacle Probability: 2%\n",
        "* Sensor Sensitivity: 95%\n",
        "* False Positive Rate (Shadows): 10%\n",
        "\n",
        "**Task:** Fill in the logic below."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n1ioFBAbP06x",
        "outputId": "8ac33c29-3068-4d96-8c15-4c567e6378c2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Actual probability of obstacle: 16.24%\n"
          ]
        }
      ],
      "source": [
        "def should_brake(p_obs, sense, fp_rate):\n",
        "    # 1. Total Evidence: P(Detection)\n",
        "    p_detection =\n",
        "\n",
        "    # 2. Posterior: P(Obstacle | Detection)\n",
        "    posterior =\n",
        "    return posterior\n",
        "\n",
        "prob_obstacle = should_brake(0.02, 0.95, 0.10)\n",
        "print(f\"Actual probability of obstacle: {prob_obstacle:.2%}\")\n",
        "# expected: Actual probability of obstacle: 16.24%"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ocrGYZ9JP06x"
      },
      "source": [
        "### Part 5: Review & Answer Key\n",
        "\n",
        "**1. The Base Rate Fallacy**\n",
        "* **Question:** Why is the 99% accurate test result so low (16.6%) in Part 2?\n",
        "* **Answer:** Because the disease is rare (1%). The 'noise' from the 99% of healthy people (even at a 5% error rate) outweighs the 'signal' from the 1% who are actually sick.\n",
        "\n",
        "**2. The 'Naive' Assumption**\n",
        "* **Question:** Why is it 'Naive' to assume words like 'Winner' and 'Money' are independent?\n",
        "* **Answer:** In human language, words appear in patterns. If you see 'Winner', you are contextually more likely to see 'Prize' or 'Money'. Naive Bayes ignores these links to stay computationally efficient.\n",
        "\n",
        "**3. Impact of Priors**\n",
        "* **Question:** If we knew the patient was in a high-risk group (Prior = 50%), how does the test trust change?\n",
        "* **Answer:** The posterior jumps to over 95%. Bayes' rule shows that our initial context (prior) is just as important as the new data (test result)."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.0"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}