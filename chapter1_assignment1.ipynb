{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lubaochuan/ml_python/blob/main/chapter1_assignment1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "352bab83",
      "metadata": {
        "id": "352bab83"
      },
      "source": [
        "## Machine Learning Workflow Assignment\n",
        "\n",
        "**Textbook:** Hands-On Machine Learning with Scikit-Learn, Keras, and TensorFlow (3rd ed.)  \n",
        "**Purpose:** Reinforce core concepts from Chapter 1\n",
        "\n",
        "---\n",
        "### Student Information\n",
        "- **Name:**  \n",
        "- **Date:**  \n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d4ef2674",
      "metadata": {
        "id": "d4ef2674"
      },
      "source": [
        "## 1Ô∏è‚É£ Setup & Reproducibility\n",
        "\n",
        "We begin by importing libraries and fixing a random seed to ensure reproducibility.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cd6a5a4b",
      "metadata": {
        "id": "cd6a5a4b",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import sklearn\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "np.random.seed(42)\n",
        "\n",
        "print(\"NumPy version:\", np.__version__)\n",
        "print(\"scikit-learn version:\", sklearn.__version__)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c55e8a40",
      "metadata": {
        "id": "c55e8a40"
      },
      "source": [
        "## 2Ô∏è‚É£ Dataset: Features and Labels\n",
        "\n",
        "We model whether a student **passes an exam** based on the number of **hours studied**.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c5b8cf6f",
      "metadata": {
        "collapsed": true,
        "id": "c5b8cf6f"
      },
      "outputs": [],
      "source": [
        "# Feature: hours studied\n",
        "X = np.array([1, 2, 3, 4, 5, 6]).reshape(-1, 1)\n",
        "\n",
        "# Label: 0 = fail, 1 = pass\n",
        "y = np.array([0, 0, 0, 1, 1, 1])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c9aeeab2",
      "metadata": {
        "id": "c9aeeab2"
      },
      "source": [
        "### ‚úçÔ∏è Concept Check 1\n",
        "\n",
        "**Which best describes `X` and `y`?**\n",
        "\n",
        "a) `X` is the label, `y` is the feature  \n",
        "b) `X` and `y` are both labels  \n",
        "c) `X` is the feature and `y` is the label  \n",
        "d) Neither is used for training  \n",
        "\n",
        "üëâ **Your answer:**  \n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f6e5a1a5",
      "metadata": {
        "id": "f6e5a1a5"
      },
      "source": [
        "## 3Ô∏è‚É£ Train / Test Split\n",
        "\n",
        "We split data so we can evaluate how well the model performs on **unseen data**.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3538c5d7",
      "metadata": {
        "id": "3538c5d7"
      },
      "outputs": [],
      "source": [
        "X_train = X[:4]\n",
        "X_test  = X[4:]\n",
        "\n",
        "y_train = y[:4]\n",
        "y_test  = y[4:]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "558f1266",
      "metadata": {
        "id": "558f1266"
      },
      "source": [
        "### ‚úçÔ∏è Concept Check 2\n",
        "\n",
        "**Why do we split data into training and test sets?**\n",
        "\n",
        "a) To make training faster  \n",
        "b) To remove noise  \n",
        "c) To measure generalization to unseen data  \n",
        "d) To reduce memory usage  \n",
        "\n",
        "üëâ **Your answer:**  \n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a6255e4a",
      "metadata": {
        "id": "a6255e4a"
      },
      "source": [
        "## 4Ô∏è‚É£ Training a Machine Learning Model\n",
        "\n",
        "We now train a logistic regression classifier.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "602282cd",
      "metadata": {
        "id": "602282cd"
      },
      "outputs": [],
      "source": [
        "model = LogisticRegression()\n",
        "model.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d5d00f37",
      "metadata": {
        "id": "d5d00f37"
      },
      "source": [
        "### ‚úçÔ∏è Concept Check 3\n",
        "\n",
        "**Which line of code actually performs learning?**\n",
        "\n",
        "a) `model = LogisticRegression()`  \n",
        "b) `model.fit(X_train, y_train)`  \n",
        "c) `model.predict(X_test)`  \n",
        "d) `import sklearn`  \n",
        "\n",
        "üëâ **Your answer:**  \n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0012ce8b",
      "metadata": {
        "id": "0012ce8b"
      },
      "source": [
        "## 5Ô∏è‚É£ Making Predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "35e736fc",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "35e736fc",
        "outputId": "47beed4c-f9fc-45b0-8b97-51c4e2a95acb"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "predictions = model.predict(X_test)\n",
        "predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ffb6bdad",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ffb6bdad",
        "outputId": "9969312f-2487-4ca9-d090-e5918202017a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "y_test"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "35e87ba1",
      "metadata": {
        "id": "35e87ba1"
      },
      "source": [
        "## 6Ô∏è‚É£ Model Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f13c8962",
      "metadata": {
        "id": "f13c8962"
      },
      "outputs": [],
      "source": [
        "accuracy = accuracy_score(y_test, predictions)\n",
        "accuracy"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "94b011a8",
      "metadata": {
        "id": "94b011a8"
      },
      "source": [
        "### ‚úçÔ∏è Concept Check 4\n",
        "\n",
        "**What does this accuracy value represent?**\n",
        "\n",
        "a) How complex the model is  \n",
        "b) The fraction of correct predictions on the test set  \n",
        "c) The number of features  \n",
        "d) How fast the model trained  \n",
        "\n",
        "üëâ **Your answer:**  \n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bbd24be2",
      "metadata": {
        "id": "bbd24be2"
      },
      "source": [
        "## 7Ô∏è‚É£ Overfitting (Conceptual)\n",
        "\n",
        "Consider a model that memorizes the training data but fails on new examples.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8894826a",
      "metadata": {
        "id": "8894826a"
      },
      "source": [
        "### ‚úçÔ∏è Concept Check 5\n",
        "\n",
        "**What does overfitting mean?**\n",
        "\n",
        "a) The model is too slow  \n",
        "b) The model predicts randomly  \n",
        "c) The model memorizes training data but generalizes poorly  \n",
        "d) The model has too few parameters  \n",
        "\n",
        "üëâ **Your answer:**  \n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3109407d",
      "metadata": {
        "id": "3109407d"
      },
      "source": [
        "## 8Ô∏è‚É£ Reflection Questions\n",
        "\n",
        "Answer in **complete sentences**.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5bac5207",
      "metadata": {
        "id": "5bac5207"
      },
      "source": [
        "### üìù Reflection 1  \n",
        "**In your own words, what is a machine learning model?**\n",
        "\n",
        "Your answer here:\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9caaa1ad",
      "metadata": {
        "id": "9caaa1ad"
      },
      "source": [
        "### üìù Reflection 2  \n",
        "**Why is accuracy sometimes not enough to evaluate a model?**\n",
        "\n",
        "Your answer here:\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3b9fef05",
      "metadata": {
        "id": "3b9fef05"
      },
      "source": [
        "### üìù Reflection 3  \n",
        "**What might happen if we evaluated the model only on training data?**\n",
        "\n",
        "Your answer here:\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5a218c0a",
      "metadata": {
        "id": "5a218c0a"
      },
      "source": [
        "### üìù Reflection 4  \n",
        "**How does this notebook reflect the ML workflow described in Chapter 1?**\n",
        "\n",
        "Your answer here:\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0a46e514",
      "metadata": {
        "id": "0a46e514"
      },
      "source": [
        "## 9Ô∏è‚É£ Optional Challenge\n",
        "\n",
        "Suppose this data came from a different school with different study habits.\n",
        "\n",
        "**What risk does this pose to the model?**\n",
        "\n",
        "‚òê Data leakage  \n",
        "‚òê Overfitting  \n",
        "‚òê Lack of generalization  \n",
        "‚òê Feature scaling  \n",
        "\n",
        "üëâ **Correct choice:**  \n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}